![[res/图01-01.png]]
# 一元回归模型
## 1. 表示
$$Y_i=\beta_1+\beta_2X_i+u_i$$
随机误差的造成因素：
1. 模型中忽略的影响因素造成的
2. 变量观测值的测量误差
3. 模型关系的设定误差
4. 其他随机因素的影响

<br />

## 2.假定条件
1. $u_i$服从概率分布
2. $u_i$具有零均值
3. $u_i$具有同方差性「<font color="#ff0000">代表性</font>」
$$Var(u_i|X_i)=E[u_i-E(u_i|X_i)]^2=E(u^2_i)=\sigma^2$$
4. $u_i$具有非序列相关性「<font color="#ff0000">无自相关</font>」
$$Cov(u_i,u_j)=E[u_i-E(u_i)][u_j-E(u_j)]=0$$
5. $u_i$服从零均值，同方差，零协方差的正态分布
6. 解释变量$X_i$非随机
7. $u_i$与$X_i$不相关，即$Cov(u_i,X_i)=0$
8. 对含有多个解释变量的线性回归模型，解释变量之间不能完全相关或高度相关

一元回归模型「通常观测不到，只能估计」：
$$Y_i=\beta_1+\beta_2X_i+u_i$$
引入估计的一元回归模型：
$$Y_i=\hat{\beta_1}+\hat{\beta_2}X_i+u_i$$
如何估计：利用“残差平方和最小”来确定直线位置：
$$RSS=\Sigma(y_i-\hat{y_i})^2=\theta_{min}$$
即最小二乘法OLS(ordinary least squares estimators)：
$$\Sigma(y_i-\hat{y_i})^2=\theta_{min}$$

<br />

## 3. 最小二乘估计量的统计特征（估计量的特征）
1. 线性特征：当$y_i$服从正态分布时，$\hat{\beta_1}$和$\hat{\beta_2}$也服从正态分布
2. 无偏性：$\hat{\beta_1}$和$\hat{\beta_2}$具有无偏性，即$E（\hat{\beta_1}）=\beta_1$ ;$E（\hat{\beta_2}）=\beta_2$ 
3. 有效性（最小方差）：在所有线性无偏估计量中，OLS估计量$\hat{\beta_1}$和$\hat{\beta_2}$的分布方差最小。
4. 渐进无偏性
5. 一致性

>高斯-马尔可夫定理：
>在古典假定条件下，OLS估计量$\hat{\beta_1}$和$\hat{\beta_2}$是总体参数$\beta_1$和$\beta_2$的最佳线性无偏估计量（best linear unbiased estimator，BLUE）

<br />

## 4. 最小二乘回归函数的性质：
1. 样本回归线通过样本均值；$(\overline{X},\overline{Y})$
2. 估计值$\hat{Y_i}$的均值等于$Y_i$实际均值$\overline{Y}$
3. 剩余项$e_i$的均值为0
4. 被解释变量估计值$\hat{Y_i}$与剩余项$e_i$不相关，$r_{\hat{Y_i},e_i}=0$
5. 解释变量估计值$\hat{X_i}$与剩余项$e_i$不相关，$r_{\hat{X_i},e_i}=0$

<br />

## 5. “拟合优度”的测量「评价回归直线对观测值拟合的好坏程度
![[res/WechatIMG161.jpeg]]
1. TSS(total sum of squares)「总离差平方和」：样本观测值与其平均值的离差平方和$\Sigma{(Y_i-\overline{Y})^2}=\Sigma{y^2_i}$
2. ESS(explained sum of squares)「回归解释平方和」：样本估计值与其平均值的离差平方和$\Sigma{(\hat{Y_i}-\overline{Y})^2}=\Sigma{\hat{y}^2_i}$
3. RSS(residual sum of squares)「残差平方和或未作出解释的平方和」：样本观测值与估计值之差的平方和$\Sigma{(Y_i-\hat{Y})^2}=\Sigma{e^2_i}$
三者关系为：
$$\Sigma{(Y_i-\overline{Y})^2}=\Sigma{(\hat{Y_i}-\overline{Y})^2}+\Sigma{(Y_i-\hat{Y})^2}$$
或：
$$\Sigma{y^2_i}=\Sigma{\hat{y}^2_i}+\Sigma{e^2_i}$$
即：
$$TSS=ESS+RSS$$
自由度：
$$(T-1)=(K-1)+(T-K)$$
可决系数$R^2$：
$$R^2=\frac{ESS}{TSS}=1-\frac{RSS}{TSS}$$
可决系数为综合度量回归模型对样本观测值拟合优度的指标，$R^2$越大，拟合优度越好；取值范围为$0\le R^2\le 1$

<br>

## 6. 回归系数的显著性检验：证明$y_i$与$x_i$之间存在回归关系
$H_0:\beta_1=0$
$H_1:\beta_1\ne0$
1. 若$\beta_1\ne0$则拒绝原假设，证明$y_i$、$x_i$之间存在回归关系
2. $T$检验(双侧检验)：
    $$t=\frac{\hat{\beta_1}-\beta_1}{\hat{SE}(\hat{\beta_1})}～t(n-2)$$
    $\left| t \right|> t_{\alpha}(n-2)$，则拒绝原假设

<br>

## 7. 回归系数的置信区间


<br>

## 8.回归模型的预测
## 9. 相关分析


<br>



# 多元回归模型
## 1. 残差的方差$S^2$：$S^2$是$\sigma^2$的无偏估计量
$$E(S^2)=\sigma^2$$

<br>

## 2. 调整后的可决系数
$$\overline{R^2}=\frac{ESS/(k-1)}{TSS/(n-1)}=1-\frac{RSS/(n-k)}{TSS/(n-1)}$$
$\overline{R^2}$与$R^2$的关系：
$$\overline{R^2}=1-(1-R^2)\frac{n-1}{n-k}$$
>当模型中增加解释变量时(从一元到多元)，$RSS$将减小
>多元$R^2$比一元$R^2$高


<br>

## 3. t检验和F检验
F检验：对全部解释变量进行显著性检验「<font color="#ff0000">单侧检验</font>」
t检验：对每个解释变量进行显著性检验「<font color="#ff0000">双侧检验</font>」

<br>

## 4. 检验程序
>1. 对一元回归模型的检验：<font color="#ff0000">直接用t检验</font>
>2. 对多元回归模型的检验：<font color="#ff0000">先F检验-再t检验</font>

<br>

### F检验：
1. $H_0：\beta_1=\beta_2=···\beta_{k-1}=0$
2. $H_1：\beta_i,i=1,2,···，k-1不全为0$
3. $F=\frac{ESS/(k-1)}{RSS/(n-k)}=\frac{R^2(n-k)}{(1-R^2)(k-1)}$
4. 若$F>F_{\alpha}(k-1,n-k)$则拒绝$H_0$，说明至少有一个解释变量与$y_i$存在回归关系。
### t检验
1. $H_0：\beta_j=0,j=1,2,····,k-1$
2. $H_1：\beta_j\ne0,j=1,2,····,k-1$
3. $t=\frac{\hat{\beta_j}}{\hat{SE}(\hat{\beta_j})}～t(n-k)$
4. 若$\left| t \right|> t_{\alpha/2}(n-k)$，拒绝原假设。
